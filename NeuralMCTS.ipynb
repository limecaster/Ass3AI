{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9026,"status":"ok","timestamp":1716825023439,"user":{"displayName":"BÂNG ĐỖ VĂN","userId":"04709157129642268526"},"user_tz":-420},"id":"1oANkSEvvmM2","outputId":"69558d54-3404-4284-f55f-6c8058d62583"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting python-chess\n","  Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n","Collecting chess<2,>=1 (from python-chess)\n","  Downloading chess-1.10.0-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: chess, python-chess\n","Successfully installed chess-1.10.0 python-chess-1.999\n"]}],"source":["!pip install python-chess"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8923,"status":"ok","timestamp":1716826510829,"user":{"displayName":"BÂNG ĐỖ VĂN","userId":"04709157129642268526"},"user_tz":-420},"id":"m4364JwEv3u1"},"outputs":[],"source":["import chess.pgn\n","import os\n","import numpy as np\n","import math\n","import random\n","from tqdm import tqdm\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2349,"status":"ok","timestamp":1716826513172,"user":{"displayName":"BÂNG ĐỖ VĂN","userId":"04709157129642268526"},"user_tz":-420},"id":"68mwtxqywjuf","outputId":"c7cb4b24-4c3c-4cf3-b742-8397da85ab50"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":86,"status":"ok","timestamp":1716826513173,"user":{"displayName":"BÂNG ĐỖ VĂN","userId":"04709157129642268526"},"user_tz":-420},"id":"vTGF6BTkuGAn"},"outputs":[],"source":["\"\"\"Data source:https://www.chess.com/forum/view/general/chess-pgn-database-over-9-million-games\n","which contains 9 million chess games in PGN format.\n","\"\"\"\n","\n","class ChessDataset(Dataset):\n","    \"\"\"Chess dataset class for batch loading PGN files.\"\"\"\n","    def __init__(self, positions, moves):\n","        self.positions = positions\n","        self.moves = moves\n","\n","    def __len__(self):\n","        return len(self.positions)\n","\n","    def __getitem__(self, idx):\n","        position = self.positions[idx]\n","        move = self.moves[idx]\n","        move_encoded = encode_move(move)\n","        # Return class index instead of one-hot encoding\n","        return position, move_encoded  # Convert to integer\n","\n","\n","def board_to_tensor(board):\n","    \"\"\"Encode the chess board to a 8x8x14 tensor representation.\"\"\"\n","    piece_map = board.piece_map()\n","    tensor = np.zeros((8, 8, 14), dtype=np.float32)\n","\n","    # Define piece types and their channels\n","    piece_channels = {\n","        chess.PAWN: 0,\n","        chess.KNIGHT: 1,\n","        chess.BISHOP: 2,\n","        chess.ROOK: 3,\n","        chess.QUEEN: 4,\n","        chess.KING: 5\n","    }\n","\n","    for square, piece in piece_map.items():\n","        row = 7 - square // 8\n","        col = square % 8\n","        channels = piece_channels[piece.piece_type]\n","        if piece.color == chess.WHITE:\n","            tensor[row, col, channels] = 1\n","        else:\n","            tensor[row, col, channels + 6] = 1\n","\n","    # Encode the player's turn channel\n","    tensor[:, :, 12] = 1 if board.turn == chess.WHITE else 0\n","\n","    # Encode castling move\n","    if board.has_kingside_castling_rights(chess.WHITE):\n","        tensor[7, 7, 13] = 1  # Kingside castling rights for white\n","    if board.has_queenside_castling_rights(chess.WHITE):\n","        tensor[7, 0, 13] = 1  # Queenside castling rights for white\n","    if board.has_kingside_castling_rights(chess.BLACK):\n","        tensor[0, 7, 13] = 1  # Kingside castling rights for black\n","    if board.has_queenside_castling_rights(chess.BLACK):\n","        tensor[0, 0, 13] = 1  # Queenside castling rights for black\n","\n","    # Encode en passant square\n","    if board.ep_square is not None:\n","        row = 7 - board.ep_square // 8\n","        col = board.ep_square % 8\n","        tensor[row, col, 13] = 1\n","\n","    return torch.tensor(tensor).permute(2, 0, 1)\n","\n","\n","def parse_pgn_to_tensor(pgn_file):\n","    \"\"\"Parse PGN file and return a list of tensors.\"\"\"\n","    positions = []\n","    moves = []\n","    print(os.getcwd())\n","    with open(pgn_file, mode=\"rt\", encoding='utf-8') as f:\n","        while True:\n","            game = chess.pgn.read_game(f)\n","            if game is None:\n","                break\n","            board = game.board()\n","            for move in game.mainline_moves():\n","                positions.append(board_to_tensor(board))\n","                moves.append(move)\n","                board.push(move)\n","    return positions, moves\n","\n","def encode_move(move):\n","    \"\"\"Encode the move to a 0-63 integer.\"\"\"\n","    from_square = move.from_square\n","    to_square = move.to_square\n","    # Combine the squares into a single index\n","    return from_square * 64 + to_square\n","\n","# Example usage\n","\n","# positions, moves = parse_pgn_to_tensor(pgn_file_path)\n","# dataset = ChessDataset(positions, moves)\n","# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_2e7RgZwFIl","outputId":"95f0f598-4dec-46d5-ce2e-df356717b957"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["class NeuralNet(nn.Module):\n","    def __init__(self, input_shape=(8, 8, 14)):\n","        \"\"\"input_shape: tuple, shape of the input tensor (height, width, channels)\n","            14 channels = 6 channels for white pieces: Pawn, Knight, Bishop, Rook, Queen, King\n","                          6 channels for black pieces:\n","                          1 channel for indicating if it's white's turn: All 1s if white, 0s if black\n","                          1 channel for special rules: E.g., castling rights or en passant availability\n","        \"\"\"\n","        super(NeuralNet, self).__init__()\n","\n","        # Define the neural network architecture\n","        # Convolutional layers\n","        self.conv1 = nn.Conv2d(input_shape[2], 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n","\n","        # Policy head\n","        self.policy_head = nn.Linear(256, 4096) # Assume there are 4096 possible moves in a turn\n","\n","        # Value head\n","        self.value_head = nn.Linear(256, 1) # Output a evaluation score between -1 and 1\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = self.pool(x)\n","\n","        x = x.view(-1, 64 * 4 * 4) # Flatten the tensor\n","\n","        x = F.relu(self.fc1(x))\n","\n","        policy = F.softmax(self.policy_head(x), dim=1)\n","        evaluation = torch.tanh(self.value_head(x))\n","\n","        return policy, evaluation\n","\n","    def train_model(self, model, train_loader, epochs, learning_rate=0.01):\n","        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","        criteration_policy = nn.CrossEntropyLoss()\n","        criteration_value = nn.MSELoss()\n","\n","        model.train()\n","        for epoch in range(epochs):\n","            total_loss_policy = 0\n","            total_loss_value = 0\n","\n","            for data in train_loader:\n","                inputs, policy_targets = data\n","                optimizer.zero_grad()\n","\n","                policy_pred, value_pred = model(inputs)\n","\n","                # Convert policy_targets to Tensor\n","                policy_targets = torch.tensor(policy_targets, dtype=torch.long)\n","\n","                policy_loss = criteration_policy(policy_pred, policy_targets)\n","                value_loss = criteration_value(value_pred, torch.zeros_like(value_pred))\n","\n","                loss = policy_loss + value_loss\n","                loss.backward()\n","                optimizer.step()\n","\n","                total_loss_policy += policy_loss.item()\n","                total_loss_value += value_loss.item()\n","\n","            print(f\"Epoch {epoch + 1}/{epochs}, Policy loss: {total_loss_policy}, Value loss: {total_loss_value}\")\n","\n","# Example usage\n","pgn_file_path = \"drive/MyDrive/Colab Notebooks/preprocessed_db.pgn\"\n","positions, moves = parse_pgn_to_tensor(pgn_file_path)\n","\n","dataset = ChessDataset(positions, moves)\n","dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n","\n","model = NeuralNet(input_shape=(8, 8, 14))\n","model.train_model(model=model, train_loader=dataloader, epochs=10)\n","torch.save(model.state_dict(), \"chess_cnn_model.pth\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9h_tLOK-wIuP"},"outputs":[],"source":["class Node:\n","    def __init__(self, board):\n","        self.M = 0\n","        self.V = 0\n","        self.board = board\n","        self.visitedMovesAndNodes = []\n","        self.nonVisitedLegalMoves = []\n","\n","        self.parent = None\n","        for move in board.legal_moves:\n","            self.nonVisitedLegalMoves.append(move)\n","\n","    def isLeaf(self):\n","        return len(self.nonVisitedLegalMoves) != 0\n","\n","    def isTerminal(self):\n","        return len(self.nonVisitedLegalMoves) == 0 and len(self.visitedMovesAndNodes) == 0\n","\n","class MCTS:\n","    def __init__(self, board, maxIter):\n","        self.root = Node(board)\n","        self.maxIter = maxIter\n","\n","    def selection(self, node):\n","        if node.isLeaf() or node.isTerminal():\n","            return node\n","\n","        maxUCTChild = None\n","        maxUCTValue = -float('inf')\n","        for move, child in node.visitedMovesAndNodes:\n","            uctValue = self.uct(child, node)\n","            if uctValue > maxUCTValue:\n","                maxUCTValue = uctValue\n","                maxUCTChild = child\n","        if maxUCTChild is None:\n","            raise ValueError (\"Could not identify child with best UCT value \")\n","\n","        return self.selection(maxUCTChild)\n","\n","\n","    def uct(self, node, parent):\n","        return node.M + math.sqrt(2 * math.log(parent.V) / node.V)\n","\n","\n","    def expansion(self, node):\n","        move = random.choice(node.nonVisitedLegalMoves)\n","        node.nonVisitedLegalMoves.remove(move)\n","        board = node.board.copy()\n","        board.push(move)\n","        child = Node(board)\n","        child.parent = node\n","        node.visitedMovesAndNodes.append((move, child))\n","        return child\n","\n","    def simulation(self, node):\n","        board = node.board.copy()\n","        while board.outcome(claim_draw = True) is None:\n","            move = random.choice(list(board.legal_moves))\n","            board.push(move)\n","\n","        payout = 0.5\n","        outcome = board.outcome(claim_draw = True)\n","\n","        if outcome == 1:\n","            payout = 1\n","        elif outcome == -1:\n","            payout = 0\n","        elif outcome == 0:\n","            payout = 0.5\n","\n","        return payout\n","\n","    def backpropagation(self, node, result):\n","        node.M = ((node.M * node.V) + result) / (node.V + 1)\n","        node.V += 1\n","\n","        if node.parent is not None:\n","            self.backpropagation(node.parent, result)\n","\n","if __name__ == \"__main__\":\n","    board = chess.Board(\"r1bqkb1r/pppp1ppp/2n2n2/4p2Q/2B1P3/8/PPPP1PPP/RNB1K1NR w KQkq - 4 4\")\n","    root = MCTS(board, 200)\n","    for i in range(root.maxIter):\n","        node = root.selection(root.root)\n","        if not node.isTerminal():\n","            node = root.expansion(node)\n","        result = root.simulation(node)\n","        root.backpropagation(node, result)\n","    root.root.visitedMovesAndNodes.sort(key = lambda x: x[1].V, reverse = True)\n","    print([(m.uci(), child.M , child.V) for m, child in root.root.visitedMovesAndNodes[0:10]])\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMe/hlQxDvELIgItOvEUn+6","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
